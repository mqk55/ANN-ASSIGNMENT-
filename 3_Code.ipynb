{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**TUTORIAL**\n",
        "1. Fetching the Dry Beans Dataset\n",
        "This line fetches the Dry Beans dataset from the UCI Machine Learning Repository using the ucimlrepo library. The dataset contains features like the area, perimeter, and shape of beans, and the goal is to classify different types of dry beans. The id=602 is a unique identifier for the dataset on the UCI repository.\n",
        "\n",
        "2. Separating Features and Target Variables\n",
        "Here, we separate the data into:\n",
        "\n",
        "X: Features (independent variables), which include various properties of the beans like size and shape.\n",
        "y: The target (dependent variable), which is the label representing the type of bean.\n",
        "\n",
        "\n",
        "3. Splitting the Dataset for Training and Testing\n",
        "This step splits the dataset into training and testing sets. We're using an 80/20 split, where:\n",
        "\n",
        "80% of the data will be used to train the model.\n",
        "20% will be used to test its accuracy.\n",
        "The parameter stratify=y ensures that the target labels are evenly distributed in both the training and testing sets. The random_state=42 ensures reproducibility (you'll get the same split every time you run the code).\n",
        "\n",
        "4. Initializing the K-Nearest Neighbors (KNN) Classifier\n",
        "We create a K-Nearest Neighbors (KNN) classifier. The KNN algorithm works by comparing new data points with the closest known data points (neighbors) and assigning the most common class label among them.\n",
        "\n",
        "Here, we set n_neighbors=5, which means the algorithm will consider the 5 nearest neighbors to make predictions.\n",
        "\n",
        "5. Training the KNN Classifier\n",
        "In this step, we train the KNN model using the training data. The .fit() function takes the training features (X_train) and the corresponding labels (y_train), and the model learns from this data.\n",
        "\n",
        "6. Making Predictions\n",
        "Once the model is trained, we use it to make predictions on the test set. The knn.predict(X_test) line generates predictions for the test data and stores them in y_pred.\n",
        "\n",
        "7. Evaluating the Model\n",
        "Now, we evaluate the model using two key metrics:\n",
        "\n",
        "Accuracy: This tells us what percentage of the predictions were correct. It's calculated using accuracy_score().\n",
        "Classification Report: This gives a detailed breakdown of the model’s performance, including precision, recall, F1-score, and support for each class (type of dry bean). The classification_report() function handles this.\n",
        "\n",
        "8. Displaying Results\n",
        "Finally, we print out:\n",
        "\n",
        "The shapes of the training and testing sets, so we know how many samples are used for each.\n",
        "The accuracy of the model on the test data, formatted to two decimal places.\n",
        "The full classification report, which provides insights into the model's performance for each class in the dataset.\n",
        "\n",
        "\n",
        "**Conclusion**\n",
        "This tutorial walks you through building a K-Nearest Neighbors classifier using the Dry Beans dataset. The dataset is split into training and testing sets, and the model is evaluated based on accuracy and classification performance. By adjusting the number of neighbors (with n_neighbors), you can experiment and see how it affects the accuracy of the classifier."
      ],
      "metadata": {
        "id": "S6gkGBqaJk68"
      },
      "id": "S6gkGBqaJk68"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baf96698-5b92-4cf3-bb65-401133f2f757",
      "metadata": {
        "id": "baf96698-5b92-4cf3-bb65-401133f2f757",
        "outputId": "ca9cb909-8ced-479c-b558-18631e7d4f44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'uci_id': 602, 'name': 'Dry Bean', 'repository_url': 'https://archive.ics.uci.edu/dataset/602/dry+bean+dataset', 'data_url': 'https://archive.ics.uci.edu/static/public/602/data.csv', 'abstract': 'Images of 13,611 grains of 7 different registered dry beans were taken with a high-resolution camera. A total of 16 features; 12 dimensions and 4 shape forms, were obtained from the grains.', 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 13611, 'num_features': 16, 'feature_types': ['Integer', 'Real'], 'demographics': [], 'target_col': ['Class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2020, 'last_updated': 'Thu Mar 28 2024', 'dataset_doi': '10.24432/C50S4B', 'creators': [], 'intro_paper': {'ID': 244, 'type': 'NATIVE', 'title': 'Multiclass classification of dry beans using computer vision and machine learning techniques', 'authors': 'M. Koklu, Ilker Ali Özkan', 'venue': 'Computers and Electronics in Agriculture', 'year': 2020, 'journal': None, 'DOI': '10.1016/j.compag.2020.105507', 'URL': 'https://www.semanticscholar.org/paper/e84c31138f2f261d15517d6b6bb8922c3fe597a1', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'Seven different types of dry beans were used in this research, taking into account the features such as form, shape, type, and structure by the market situation. A computer vision system was developed to distinguish seven different registered varieties of dry beans with similar features in order to obtain uniform seed classification. For the classification model, images of 13,611 grains of 7 different registered dry beans were taken with a high-resolution camera. Bean images obtained by computer vision system were subjected to segmentation and feature extraction stages, and a total of 16 features; 12 dimensions and 4 shape forms, were obtained from the grains.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '1.) Area (A): The area of a bean zone and the number of pixels within its boundaries.\\r\\n2.) Perimeter (P): Bean circumference is defined as the length of its border.\\r\\n3.) Major axis length (L): The distance between the ends of the longest line that can be drawn from a bean.\\r\\n4.) Minor axis length (l): The longest line that can be drawn from the bean while standing perpendicular to the main axis.\\r\\n5.) Aspect ratio (K): Defines the relationship between L and l.\\r\\n6.) Eccentricity (Ec): Eccentricity of the ellipse having the same moments as the region.\\r\\n7.) Convex area (C): Number of pixels in the smallest convex polygon that can contain the area of a bean seed.\\r\\n8.) Equivalent diameter (Ed): The diameter of a circle having the same area as a bean seed area.\\r\\n9.) Extent (Ex): The ratio of the pixels in the bounding box to the bean area.\\r\\n10.)Solidity (S): Also known as convexity. The ratio of the pixels in the convex shell to those found in beans.\\r\\n11.)Roundness (R): Calculated with the following formula: (4piA)/(P^2)\\r\\n12.)Compactness (CO): Measures the roundness of an object: Ed/L\\r\\n13.)ShapeFactor1 (SF1)\\r\\n14.)ShapeFactor2 (SF2)\\r\\n15.)ShapeFactor3 (SF3)\\r\\n16.)ShapeFactor4 (SF4)\\r\\n17.)Class (Seker, Barbunya, Bombay, Cali, Dermosan, Horoz and Sira)\\r\\n', 'citation': None}}\n",
            "               name     role         type demographic  \\\n",
            "0              Area  Feature      Integer        None   \n",
            "1         Perimeter  Feature   Continuous        None   \n",
            "2   MajorAxisLength  Feature   Continuous        None   \n",
            "3   MinorAxisLength  Feature   Continuous        None   \n",
            "4       AspectRatio  Feature   Continuous        None   \n",
            "5      Eccentricity  Feature   Continuous        None   \n",
            "6        ConvexArea  Feature      Integer        None   \n",
            "7     EquivDiameter  Feature   Continuous        None   \n",
            "8            Extent  Feature   Continuous        None   \n",
            "9          Solidity  Feature   Continuous        None   \n",
            "10        Roundness  Feature   Continuous        None   \n",
            "11      Compactness  Feature   Continuous        None   \n",
            "12     ShapeFactor1  Feature   Continuous        None   \n",
            "13     ShapeFactor2  Feature   Continuous        None   \n",
            "14     ShapeFactor3  Feature   Continuous        None   \n",
            "15     ShapeFactor4  Feature   Continuous        None   \n",
            "16            Class   Target  Categorical        None   \n",
            "\n",
            "                                          description   units missing_values  \n",
            "0   The area of a bean zone and the number of pixe...  pixels             no  \n",
            "1   Bean circumference is defined as the length of...    None             no  \n",
            "2   The distance between the ends of the longest l...    None             no  \n",
            "3   The longest line that can be drawn from the be...    None             no  \n",
            "4   Defines the relationship between MajorAxisLeng...    None             no  \n",
            "5   Eccentricity of the ellipse having the same mo...    None             no  \n",
            "6   Number of pixels in the smallest convex polygo...    None             no  \n",
            "7   Equivalent diameter: The diameter of a circle ...    None             no  \n",
            "8   The ratio of the pixels in the bounding box to...    None             no  \n",
            "9   Also known as convexity. The ratio of the pixe...    None             no  \n",
            "10  Calculated with the following formula: (4piA)/...    None             no  \n",
            "11                Measures the roundness of an object    Ed/L             no  \n",
            "12                                               None    None             no  \n",
            "13                                               None    None             no  \n",
            "14                                               None    None             no  \n",
            "15                                               None    None             no  \n",
            "16  (Seker, Barbunya, Bombay, Cali, Dermosan, Horo...    None             no  \n"
          ]
        }
      ],
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "dry_bean = fetch_ucirepo(id=602)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = dry_bean.data.features\n",
        "y = dry_bean.data.targets\n",
        "\n",
        "# metadata\n",
        "print(dry_bean.metadata)\n",
        "\n",
        "# variable information\n",
        "print(dry_bean.variables)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "873526b1-40b7-443c-a47c-14630eb3b53b",
      "metadata": {
        "id": "873526b1-40b7-443c-a47c-14630eb3b53b",
        "outputId": "9e308336-1987-43c6-85a3-dcb6913a285e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\anaconda\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training feature set shape: (10888, 16)\n",
            "Testing feature set shape: (2723, 16)\n",
            "Training target set shape: (10888, 1)\n",
            "Testing target set shape: (2723, 1)\n",
            "Accuracy of the K-Nearest Neighbors Classifier: 0.72\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    BARBUNYA       0.52      0.51      0.51       265\n",
            "      BOMBAY       1.00      1.00      1.00       104\n",
            "        CALI       0.66      0.66      0.66       326\n",
            "    DERMASON       0.81      0.89      0.85       709\n",
            "       HOROZ       0.75      0.68      0.72       386\n",
            "       SEKER       0.75      0.60      0.67       406\n",
            "        SIRA       0.66      0.72      0.69       527\n",
            "\n",
            "    accuracy                           0.72      2723\n",
            "   macro avg       0.74      0.72      0.73      2723\n",
            "weighted avg       0.72      0.72      0.72      2723\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Fetch the Dry Beans dataset\n",
        "dry_bean = fetch_ucirepo(id=602)\n",
        "\n",
        "# Data separation\n",
        "X = dry_bean.data.features  # Features\n",
        "y = dry_bean.data.targets    # Target variable\n",
        "\n",
        "# Applying train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Initialize the K-Nearest Neighbors Classifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors\n",
        "\n",
        "# Fit the model on the training data\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_report_output = classification_report(y_test, y_pred)\n",
        "\n",
        "# Output the results\n",
        "print(f\"Training feature set shape: {X_train.shape}\")\n",
        "print(f\"Testing feature set shape: {X_test.shape}\")\n",
        "print(f\"Training target set shape: {y_train.shape}\")\n",
        "print(f\"Testing target set shape: {y_test.shape}\")\n",
        "print(f\"Accuracy of the K-Nearest Neighbors Classifier: {accuracy:.2f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "449b6a42-1cdf-40b3-9179-af0b99dd3c9f",
      "metadata": {
        "id": "449b6a42-1cdf-40b3-9179-af0b99dd3c9f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}